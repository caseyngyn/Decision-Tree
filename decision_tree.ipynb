{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import statistics\n",
    "from statistics import mode\n",
    "import pprint\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "def open_file(filename):\n",
    "    if filename == 'tic-tac-toe.data':\n",
    "        col_name = ['top-l','top-m','top-r','mid-l','mid-m','mid-r','bot-l','bot-m','bot-r','class']\n",
    "        df = pd.read_csv(filename,names = col_name)   \n",
    "    if filename == 'balance-scale.data':\n",
    "        col_name = ['class','lft-weight','lft-dist','rght-weight','rght-dist']\n",
    "        df = pd.read_csv(filename,names = col_name)\n",
    "        #move class to the last row\n",
    "        cols = df.columns.tolist()\n",
    "        cols = cols[1:] + cols[:1]\n",
    "        df = df[cols]\n",
    "    if filename == 'agaricus-lepiota.data':\n",
    "        col_name = ['class','cap-shape','cap-surface','cap-color','bruises','odor','gill-attachment','gill-spacing','gill-size',\n",
    "        'gill-color','stalk-shape','stalk-root','stalk-surface-above-ring','stalk-surface-below-ring', 'stalk-color-above-ring',\n",
    "        'stalk-color-below-ring','veil-type','veil-color','ring-number','ring-type','spore-print-color','population','habitat']\n",
    "        df = pd.read_csv(filename,names = col_name)\n",
    "        #move class to the last row\n",
    "        cols = df.columns.tolist()\n",
    "        cols = cols[1:] + cols[:1]\n",
    "        df = df[cols]\n",
    "    if filename == 'car.data':\n",
    "        col_name  = ['Buying','Maint','Doors','Persons','Lug Boot','Safety','class']\n",
    "        df = pd.read_csv(filename,names = col_name)\n",
    "\n",
    "    if filename =='zoo.data':\n",
    "        #import the dataset\n",
    "        col_name = ['animal_name','hair','feathers','eggs','milk','airborne','aquatic','predator','toothed','backbone','breathes','venomous','fins','legs','tail','domestic','catsize','class']\n",
    "        df = pd.read_csv(filename,names =col_name)\n",
    "        #we drop this feature,since this is not good feature to split the data\n",
    "        df = df.drop('animal_name',axis=1)\n",
    "    #print(df)\n",
    "    #split into training and testing \n",
    "    #shuffle data to randomize\n",
    "    #80% training, %20 test\n",
    "    #shuffle\n",
    "    df = df.sample(frac=1)\n",
    "    training = df.sample(frac = 0.8)\n",
    "    remainder = df.drop(training.index)\n",
    "    test = remainder.sample(frac = 0.2)\n",
    " \n",
    "    return df,test,training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def entropy(df):\n",
    "    #entropy(S) = summation { -p*log_2(p)}\n",
    "    target_col = df.keys()[-1]\n",
    "    classifiers = df[target_col].unique()\n",
    "    e = 0\n",
    "    for classifier in classifiers:\n",
    "        #print('entropy eq:', classifier)\n",
    "        frac = df[target_col].value_counts()[classifier] /len(df[target_col])\n",
    "        e += -frac*math.log2(frac)\n",
    "    return e\n",
    "\n",
    "def gain(df,split_attribute_name):\n",
    "    \"\"\" \n",
    "    #info gain of aattribute\n",
    "    #gain(s,a) = entropy(s) - summation for v in values(A){ (|S_v|/|S|)*Entropy(S_v) }\n",
    "    \"\"\"\n",
    "    \n",
    "    target_col = df.keys()[-1]\n",
    "    values = df[split_attribute_name].unique()\n",
    "    ''' \n",
    "    print('classifier',classifiers)\n",
    "    for i in values:\n",
    "        print(i)\n",
    "    print('value',values)\n",
    "    '''\n",
    "    s = entropy(df)\n",
    "    #print('s',s)\n",
    "    summation = 0\n",
    "    for v in values:\n",
    "        frac = df[split_attribute_name].value_counts()[v]/(len(df[split_attribute_name]))\n",
    "        #print('v',v)\n",
    "        sv = df[df[split_attribute_name] == v]\n",
    "        #print(sv)\n",
    "        entropy_sv = entropy(sv)\n",
    "        #print('sv',entropy_sv)\n",
    "        summation += frac *entropy_sv\n",
    "    g = s - summation\n",
    "    \n",
    "    return g\n",
    "\n",
    "def find_best_feature(df):\n",
    "    \"\"\" \n",
    "    traverse throught each attribute and append to an array\n",
    "    return the best attribute\n",
    "    \"\"\"\n",
    "    info = []\n",
    "    #print('df')\n",
    "    #print(df)\n",
    "    #print('keys',df.keys()[:-1])\n",
    "\n",
    "    for key in df.keys()[:-1]:\n",
    "        #print('k',key)\n",
    "        info.append(gain(df,key))\n",
    "    ''' \n",
    "    print('info',info)\n",
    "    print('npDFS', np.argmax(info))\n",
    "    print('keys',df.keys()[:-1][np.argmax(info)])\n",
    "    #return the best KEY based on the value of \n",
    "    '''\n",
    "    #attribute of best info\n",
    "    return df.keys()[:-1][np.argmax(info)]\n",
    "\n",
    "def decision_tree(df,og_df,features,target_attribute_name=\"class\",parent_node_class = None):\n",
    "    \"\"\"\n",
    "    recursively creates the tree\n",
    "    data structure used: nested dicts\n",
    "    \"\"\"\n",
    "    #If all target_values have the same value,return this value\n",
    "    if len(np.unique(df[target_attribute_name])) <= 1:\n",
    "        #print('have no more data')\n",
    "        #print(np.unique(df[target_attribute_name])[0])\n",
    "        return np.unique(df[target_attribute_name])[0]\n",
    "    \n",
    "    #if dataset is empty\n",
    "    elif len(df) ==0:\n",
    "        #print('len0',np.unique(og_df[target_attribute_name])[np.argmax(np.unique(og_df[target_attribute_name],return_counts = True)[1])])\n",
    "        return np.unique(og_df[target_attribute_name])[np.argmax(np.unique(og_df[target_attribute_name],return_counts = True)[1])]\n",
    "    #if feature is empty\n",
    "    elif len(features) ==0:\n",
    "        return parent_node_class\n",
    "    #if none base conditions hold true grow tree\n",
    "\n",
    "    else:\n",
    "        parent_node_class = np.unique(df[target_attribute_name])[np.argmax(np.unique(df[target_attribute_name],return_counts=True)[1])]\n",
    "        #print('pnc',parent_node_class)\n",
    "\n",
    "        best_feature = find_best_feature(df)\n",
    "            \n",
    "        #Create the tree structure of best feature recieved from df\n",
    "        tree = {best_feature:{}}\n",
    "\n",
    "        #Remve the feature with the best info gain\n",
    "        features = [i for i in features if i!= best_feature]\n",
    "\n",
    "        for value in np.unique(df[best_feature]):\n",
    "            value = value\n",
    "            sub_data = df.where(df[best_feature]==value).dropna()\n",
    "            #call recursion\n",
    "            subtree = decision_tree(sub_data,og_df,features,target_attribute_name,parent_node_class)\n",
    "            #add subtree\n",
    "            tree[best_feature][value] = subtree\n",
    "\n",
    "        return tree\n",
    "    \n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(query,tree,default =1):\n",
    "    \"\"\"\n",
    "    traverse through the test\n",
    "    if the key which is the  attribute is in the tree\n",
    "        try accessing it\n",
    "    else return 1\n",
    "    if you can access it and we check its a dict\n",
    "    recursivly call the function\n",
    "    otherwise return what class it is \n",
    "    \"\"\"\n",
    "    for key in list(query.keys()):\n",
    "        if key in list(tree.keys()):\n",
    "            try:\n",
    "                result = tree[key][query[key]]\n",
    "            except:\n",
    "                return default\n",
    "\n",
    "            result = tree[key][query[key]]\n",
    "            if isinstance(result,dict):\n",
    "                return predict(query,result)\n",
    "            else:\n",
    "                return result\n",
    "\n",
    "def test(data, tree):\n",
    "    \"\"\"\n",
    "    populates the predicted df with the prediction or 1 if incorrect\n",
    "    to calc accuracy calc the ones that are not equal too 1 and div by len of data passed in and take percentage\n",
    "    return lisst of predicted class\n",
    "    \"\"\"\n",
    "    # [{column -> value}, â€¦ , {column -> value}]\n",
    "    queries = data.iloc[:,:-1].to_dict(orient = 'records')\n",
    "    predicted =pd.DataFrame(columns = [\"predicted\"])\n",
    "    #print('p',predicted)\n",
    "    #print('queries',queries)\n",
    "    #print(data)\n",
    "    #print('------------------')\n",
    "    #predictions for what the index in the data is\n",
    "    for i in range(len(data)):\n",
    "        predicted.loc[i,\"predicted\"] = predict(queries[i],tree,1.0)\n",
    "    #print(predicted)\n",
    "    p = predicted[\"predicted\"].to_numpy()\n",
    "    d = data[\"class\"].to_numpy()\n",
    "    ratio = np.sum(p==d)\n",
    "    #print(ratio)\n",
    "    #print(len(data))\n",
    "    print(\"The Prediction accuracy is:\",ratio/len(data)*100,'%')\n",
    "    return p\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Prediction accuracy is: 100.0 %\n",
      "The Prediction accuracy is: 85.5072463768116 %\n",
      "The Prediction accuracy is: 78.26086956521739 %\n",
      "The Prediction accuracy is: 84.05797101449275 %\n",
      "The Prediction accuracy is: 75.36231884057972 %\n",
      "The Prediction accuracy is: 78.26086956521739 %\n",
      "The Prediction accuracy is: 65.21739130434783 %\n",
      "The Prediction accuracy is: 75.36231884057972 %\n",
      "The Prediction accuracy is: 78.26086956521739 %\n",
      "The Prediction accuracy is: 75.36231884057972 %\n",
      "The Prediction accuracy is: 75.36231884057972 %\n",
      "The Prediction accuracy is: 79.71014492753623 %\n",
      "The Prediction accuracy when doing the random forest is: 84.05797101449275 %\n"
     ]
    }
   ],
   "source": [
    "def most_frequent(l):\n",
    "    return mode(l)\n",
    "\n",
    "def random_forest(df,testing):\n",
    "    \"\"\"\n",
    "    split df into log2(len(df))\n",
    "    for each subset\n",
    "        make sub decsion tree\n",
    "    run prediction for each subtree\n",
    "    get cols from rows of nested list\n",
    "    get most occured from each col\n",
    "    get ratio of how many guessed correctly \n",
    "    get percentage of guessed right\n",
    "    \"\"\"\n",
    "\n",
    "    #print(df)\n",
    "    #print(testing[\"class\"])\n",
    "    #print(len(testing[\"class\"]))\n",
    "    splits =int(math.log2(len(df)))\n",
    "    split_trainng = np.array_split(df,splits)\n",
    "    \"\"\" \n",
    "    for i in split_trainng:\n",
    "        print('-----')\n",
    "        print(i)\n",
    "        print('-------')\n",
    "    \"\"\"\n",
    "    trees = []\n",
    "    for subset in split_trainng:\n",
    "        tree = decision_tree(subset,subset,subset.columns[:-1])\n",
    "        trees.append(tree)\n",
    "    predictions = []\n",
    "    for tree in trees:\n",
    "        prediction = test(testing,tree)\n",
    "        predictions.append(prediction)\n",
    "        \"\"\" \n",
    "        print('---------')\n",
    "        pprint.pprint(i)\n",
    "        print('---------')\n",
    "        \"\"\"\n",
    "    \"\"\" \n",
    "    print('pred')\n",
    "    for i in predictions:\n",
    "        print('---------')\n",
    "        print(i)\n",
    "        print('---------')\n",
    "    \"\"\"\n",
    "    tpredictions = list(zip(*predictions))\n",
    "    guesses = pd.DataFrame(columns = [\"predicted\"])\n",
    "    for i in range(len(tpredictions)):\n",
    "        #guesses.append(most_frequent(i))\n",
    "        guesses.loc[i,\"predicted\"] = most_frequent(tpredictions[i])\n",
    " \n",
    "    \"\"\"\n",
    "    print('tpred')\n",
    "    for i in tpredictions:\n",
    "        print('---------')\n",
    "        print(i)\n",
    "        print('---------')\n",
    "    \"\"\"\n",
    "\n",
    "    g = guesses[\"predicted\"].to_numpy()\n",
    "    t = testing[\"class\"].to_numpy()\n",
    "    ratio = np.sum(g==t)\n",
    "    print(\"The Prediction accuracy when doing the random forest is:\",ratio/len(testing)*100,'%')\n",
    "\n",
    "    return\n",
    "def main():\n",
    "    #filename = 'zoo.data'\n",
    "    filename = 'car.data'\n",
    "    #filename = 'agaricus-lepiota.data'\n",
    "    df,testing,training = open_file(filename)\n",
    "    tree = decision_tree(training,training,training.columns[:-1])\n",
    "    #pprint.pprint(tree)\n",
    "    y = test(training,tree)\n",
    "    x = test(testing,tree)\n",
    "    random_forest(training,testing)\n",
    "    return\n",
    "\n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3d1ca52bb081b6c43f309b4b16d9d8dff2d553c1a33574d9a286afe62bc8ecd2"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit ('python39': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
